{
    "paper_id": "P01",
    "repo_name": "siegelz/core-bench",
    "env": {
        "type": "conda",
        "setup_commands": [
            "git clone https://github.com/siegelz/core-bench.git",
            "cd core-bench",
            "micromamba create --name core-bench python=3.9",
            "micromamba activate core-bench"
        ]
    },
    "steps": [
        {
            "id": "install_dependencies",
            "description": "Install dependencies",
            "working_dir": "core-bench",
            "commands": [
                "micromamba install -y -f requirements.txt"
            ],
            "expected_artifacts": ["core-bench directory with installed dependencies"]
        },
        {
            "id": "decrypt_dataset",
            "description": "Decrypt dataset",
            "working_dir": "core-bench",
            "commands": [
                "gpg --output benchmark/dataset/core_test.json --decrypt benchmark/dataset/core_test.json.gpg"
            ],
            "expected_artifacts": ["Decrypted core_test.json file in benchmark/dataset directory"]
        },
        {
            "id": "run_main_experiment",
            "description": "Run main experiment",
            "working_dir": "core-bench",
            "commands": [
                "python3 main.py --experiment_name test_coreagent_gpt4o_c-4 --agent_dir agents/AutoGPT-CORE --dataset_file benchmark/dataset/core_test.json --no_gpu --task_limit 1 --benchmark_level codeocean_hard --agent_script coreagent_hard_gpt4o.sh --verbose"
            ],
            "expected_artifacts": ["Report.json files in the environment directories of each task"]
        }
    ]
}